---
title: "EuroFab Design review"
author: "Eurofab team"
# institute: "Charles University"
date: "2024-10-04"
format:
    revealjs:
        theme: [default, ../assets/reveal.scss]
        logo: ../assets/icon.svg
        menu: false
        transition: slide
        navigation-mode: linear
        controls-layout: edges
        incremental: true
        progress: true
        include-in-header: ../assets/font.html
        title-slide-attributes:
            data-background-image: ../assets/logos.png
            data-background-size: 20%
            data-background-position: 50% 90%
---

# Reference Data selection
## AI data
### Satellite imagery
* Sentinel-2 composite (Corbane et al.), RGB, 10px/m
* temporal/spatial flexibility
* analysis-ready; cloud-free
* suitability for downstream ML tasks

---

### Urban fabric classes

* Spatial signatures framework (Arribas-Bel & Fleischmann 2022)
* Proxy due to its conceptual alignment with urban characterization

![](../figures/202412_december_turing/signatures_london.png){.nostretch fig-align="top" height="200"}


# Algorithm Design

## AI Modelling using Satellite Imagery

---

### Overview

**Classification vs Segmentation**

* Classification: Single label per tile
* Segmentation: Pixel-level classification

![](../figures/202412_december_turing/classification_vs_segmentation.png){.nostretch fig-align="top" height="200"}

---

### Experiments

**Overall approach comparison**

- A: Baseline (embeddings + ML model)
- B: Segmentation (fine-tuned Clay model)
- C: Classification (fine-tuned Clay model

→ choose final model approach

---

**Model adaptations (baseline approach)**

- Variation of baseline (ordinal)
- Smaller tile size
- Sampling method experiments


---

### Data Preprocessing

**Segmentation dataset**

    - 224 x 224 pixel tiles
    - Train: 21,402 tiles; Test: 5,351 tiles

**Classification dataset**

    - 56 x 56 pixel tiles
    - Train: 342,648 tiles; Test: 61,074 tiles

![](../figures/202412_december_turing/tile_size_comp.png){.nostretch fig-align="right" height="200"}


---

#### Challenges
**Class imbalance**

  - Uneven distribution across urban fabric classes

**Shared train/test split**

  - Ensures consistent comparison between tasks (segmentation/classification)

![](../figures/202412_december_turing/unbalanced.png){.nostretch fig-align="left" height="250"}
![](../figures/202412_december_turing/sampling.png){.nostretch fig-align="right" height="250"}


---

### Model Architectures
#### Approach A: Baseline Embedding

1. **Pipeline**

   - Generate embeddings (SatlasPretrain model)
   - Predict classes using XGBoost

---

1. **Pipeline**

![](../figures/202412_december_turing/baseline.png){.nostretch fig-align="center" height="400"}

---

2. **Enhancements**
   - Added spatial context using H3 hex lat/lon

![](../figures/202412_december_turing/hex_level5.png){.nostretch fig-align="center" height="420"}

---

#### Approach B: Segmentation Models

- Fine-tuned three models

  - **Satlas**: SwinT; 302M labels
  - **Clay**: MAE/ViT; 70M labels
  - **Prithvi**: MAE/ViT; 250PB data

---

**Recap** 

| Metric            | Satlas | Clay (Best) | Prithvi |
|--------------------|--------|-------------|---------|
| Weighted Accuracy | 0.57   | **0.72**    | 0.62    |
| IoU               | 0.33   | **0.58**    | 0.41    |
| F1 Score          | 0.41   | **0.69**    | 0.58    |
| Training Time (epoch)  | 9 min  | 8 min       | 20 min  |

→ Clay model outperformed other models

---

**Clay model**

![](../figures/202412_december_turing/clay_model.png){.nostretch fig-align="center" width="900"}

→ trained with focal loss

---


#### Approach C: Classification

- Fine-tuned **Clay model** for classification task
- Dataset: 56 x 56 px tiles


---


### Evaluation metrics approach comparison

**Pixel-level comparison**

- **F1 Score**: Balance between precision and recall, highlighting overall model performance for all classes.
- **Macro Accuracy**: Averages accuracy across classes, treating each class equally regardless of size.
- **IoU**: Quantifies the overlap between predicted and true regions, indicating segmentation accuracy.


---

::: {.small-table}
| Approach | Global Ac. | Macro Acc. | F1 Score | IoU |
|----------|----------------|----------------|----------|-----|
|**A**: Class. (embed.)| 0.76 (0.66) | 0.22 (0.13) | 0.23 | 0.63 |
|**A**: Class. + H3 lvl 5| **0.87** (0.82) | **0.42** (0.35) | **0.45** | **0.79** |
|**B**: Seg. (Clay) | 0.73 | 0.31 | 0.30 | 0.58 |
|**C**: Class. (Clay) | 0.59 (0.68) | 0.09 | 0.12 | 0.38 |
::: 

---

**Comparison of approach B & C**

- Overprediction of dominant class
- Segmentation boundaries

![](../figures/202412_december_turing/comparison_B_C.png){.nostretch fig-align="center" width="700"}


---

- **Key Findings**:
  - Embedding model (baseline) outperformed fine-tuned foundation model approaches
  - Clay model outperformed others in segmentation

- **Challenges**:
  - Handling class imbalance
  - Segmentation: non directly visual boundaries in images

---

### Additional model adaptations (baseline model)

- Ordinal approach
- Tile size
- Sampling experiments

---

#### Ordinal approach

Signatures are not strictly categorical (some are closer than other ones) 

```
ordinal_mapping = {
    'Wild countryside': 0,
    'Countryside agriculture': 1,
    'Urban buffer': 2,
    'Open sprawl': 3,
    'Disconnected suburbia': 4,
    'Accessible suburbia': 5,
    'Warehouse/Park land': 6,
    'Gridded residential quarters': 7,
    'Connected residential neighbourhoods': 8,
    'Dense residential neighbourhoods': 9,
    'Dense urban neighbourhoods': 10,
    'Urbanity': 11,
}
```

---

#### Ordinal approach

- Mean Absolute Error: 0.28 
- Mean Squared Error: 0.28 
- R² Score: 0.62

![](../figures/202412_december_turing/sankey.png){.nostretch fig-align="center" width="600"}


---

#### Comparison of baseline approaches

::: {.small-table}
| Approach | Global Acc. | Macro Acc. | F1 Score | IoU |
|----------|----------------|----------------|----------|-----|
|A: Class. (embed.)| 0.76 (0.66) | 0.22 (0.13) | 0.23 | 0.63 |
|A: Class. + H3 lvl 5 | **0.87** (0.82) | **0.42** (0.35) | **0.45** | **0.79** |
|A:  Class. + H3 + ordinal | 0.80 (0.80) | 0.26 (0.26) | 0.26 | 0.69 |
:::

---

### Varying tile size

- Motivated by more useful tile size for policy applications
- Map creation (less missing data) 
- 25 x 25 px tiles (250x250m)

---

### Varying tile size

<div style="font-size: small;">

| **Tile size**   | **Model**    | **Global Acc.** | **Macro Acc.** | **F1** |
|------------------|-----------------------|-------------|-------------|-------------|
| **56x56**      | Class. (embed.)               | 0.76         | 0.22     | 0.23                   |
| 56x56      | Class. (embed.) + H3 lvl 5 (cat) | **0.87 **     | 0.42     | 0.45               |
| 56x56      | Class. (embed.) + H3 lvl 5 (lat/lon) | **0.87** | 0.39         | 0.42                   |
| 56x56      | Class. (embed.) + H3 lvl 5 ordinal | 0.80      | 0.26         | 0.26                   |
| **25x25**      | Class. (embed.)                  | 0.73                | 0.31                | 0.30                   |
| 25x25     | Class. (embed.) + H3 lvl 5 (lat/lon) | 0.81           | **0.46**                | **0.53**       |

</div>

---


### Sampling experiments

<div style="font-size: smaller;">

|Random Sampling | H3 Split (Resolution 3) |
|-----------------|------------------------| 
|Ensures diverse samples but risks spatial leakage, overestimating performance.   |Reduces spatial leakage for realistic generalization but may under/over-sample signature types. |
|Benefits training diversity but may inflate results due to proximity of train/test data.   |  Highlights spatial independence but may penalize heterogeneity within regions. |

</div>

---

#### Sampling experiments

**Random sampling**

![](../figures/202412_december_turing/train_df.png){.nostretch fig-align="left" height="400"}
![](../figures/202412_december_turing/test_df.png){.nostretch fig-align="right" height="400"}


---

#### Regional sampling (H3)

- train: blue
- test: orange

![](../figures/202412_december_turing/sampling_h3_3.png){.nostretch fig-align="center" height="400"}


---

#### Sampling experiments

**Random sampling**

- F1: 0.53
- Macro Acccuracy: 0.46

**H3 sampling**
Overall Metrics (5 Iterations; random sample across 26 H3 (resolution 3) hexagons):

- Mean F1 score: 0.14 
- Mean macro accuracy: 0.13

---

#### Model choice based on objective

Goal

- Local prediction:  random sampling might align better with your objectives, as it focuses on learning detailed local variations.
- Regional or global prediction: regional splitting might be more suitable because it ensures the model learns broader generalization patterns.

→ Deployment on all data in the end; (sampling only for reporting accuracy)

---

## Next steps

- Train final model on all 25x25 tiles (embeddings)
    - Embeddings model + H3 level 5 lat/lon 
- Product: Prediction pipeline 
    - Make predictions across time (years)  

