---
title: "Progress meeting October"
subtitle: "AI model design"
author: "Eurofab team"
institute: "Alan Turing Institute"
# date: "today"
format:
  revealjs:
    theme: 
      - default
      - ../assets/reveal.scss
    logo: ../assets/icon.svg
    menu: false
    transition: slide
    navigation-mode: linear
    controls-layout: edges
    progress: true
    include-in-header: ../assets/font.html
    title-slide-attributes:
      data-background-image: ../assets/logos.png
      data-background-size: 20%
      data-background-position: 50% 90%
---

# Overview
- **AI model design:** June-October 2024
- **AI model development and training:** September-November 2024
- **European space-time urban strategy:** December-March 2025


## Review: AI model design
* **Scale:** Pixel vs patch (size)
* **Task:** Classification vs segmentation
* **Model:** Network architectures and foundation models


# Baseline

![](../figures/progress_october_turing/baseline.png){.nostretch fig-align="center" height="400"}


---

## Baseline: Results

![](../figures/progress_october_turing/baseline_tile_level.png){.nostretch fig-align="center" height="420"}


# WP 202: AI model design

![](../figures/progress_october_turing/overview.png){.nostretch fig-align="center"}


## Data preprocessing

* 224 x 224 x 3 image tiles
    - 26,942 tiles (.tif)

* Labels:
    - Spatial signatures (.tif)

- Train/test split: stratified 80/20% (stratified by distribution in dataset)

---

### Train/test 
80/20%
![](../figures/progress_october_turing/train_df.png){.nostretch fig-align="left" height="400"}
![](../figures/progress_october_turing/test_df.png){.nostretch fig-align="right" height="400"}


---

### Unbalanced dataset

![](../figures/progress_october_turing/unbalanced.png){.nostretch fig-align="center" height="420"}

---

### Example

![](../figures/progress_october_turing/random_sample.png){.nostretch fig-align="center" height="420"}

---


## Model design
![](../figures/progress_october_turing/example.png){.nostretch fig-align="center" height="400"}

## Model design
![](../figures/progress_october_turing/setup.png){.nostretch fig-align="center"}


## Backbone: foundation models

- Satlas
- Clay
- IBM/NASA (Prithvi)

![](../figures/202408_progress_august_AT/foundation_models.png){.nostretch fig-align="center" height="200"}


---

## Comparison of backbones

| Model | Architecture | #Labels | Images |
|---------|:-----|------:|:------:|
| Satlas   | SwinT    | 302M | Sentinel-2  |
| Clay     | MAE/ViT  | 70M  |Sentinel-2/Landsat/NAIP/LINZ |
| Prithvi | MAE/ViT  | 250 PB |  Sentinel-2/Landsat   |


## Loss

* **CrossEntropy Loss** ("ce"):
    - penalizes pixel-wise misclassifications

* **Focal Loss** ("focal"):
    - reduces the contribution of easily classified examples and puts more weight on hard-to-classify pixels.

## Validation metric

* **IoU** (Intersection over Union)
    - Overlap between predicted and ground truth segmentations; 0 (no overlap) to 1 (perfect overlap).

* **F1 Score** (Weighted)
    - Balancing precision (how much of the prediction is correct) and recall (how much of the actual segmentation is captured).

* **Accuracy** (Weighted)
    - Percentage of correctly classified pixels.

---

### Model A: Satlas
![](../figures/progress_october_turing/satlas_model.png){.nostretch fig-align="center" height="400"}

---

### Model B: Clay
![](../figures/progress_october_turing/clay_model.png){.nostretch fig-align="center" height="400"}

---

### Model C: Prithvi
![](../figures/progress_october_turing/prithvi_model.png){.nostretch fig-align="center" height="400"}


---


### Results: fine-tuning

| Model          | Satlas | Clay   | Prithvi |
|----------------|--------|--------|---------|
| Run time (per epoch) (with GPU)  | 9 mins | 8 mins | 20 mins |
| # parameters      | 90M | 86M  | 120M |
| Implementation | 5/10   | 6/10   | 7/10    |
| Hyperparameter tracking   | Own setup | Wandb.ai | Tensorboard |

---

### Results: fine-tuning 10 epochs

|           | Satlas | Clay   | Prithvi |
|----------------|--------|--------|---------|
| Accuracy (weighted)     | 0.57   | **0.72**   | 0.62    |
| IoU (weighted) (0-1)    | 0.33  | **0.58**  | 0.41   |
| F1 (weighted)          | 0.41  | **0.69**  | 0.58   |


Without hyperparameter tuning!

---

### Results: fine-tuning w/ focal loss

|           | Satlas | Clay   | Prithvi |
|----------------|--------|--------|---------|
| Accuracy (weighted)      | 0.25  | **0.72**   | 0.59     |
| IoU (weighted) (0-1)  | 0.2  | **0.58**  | 0.42   |
| F1 (weighted)     | 0.21  | **0.69**  | 0.59    |

---


## Prithvi: CE vs focal loss

![](../figures/progress_october_turing/class_acc_ce_loss.png){.nostretch fig-align="left" height="280"}
![](../figures/progress_october_turing/class_acc_focal_loss_prithvi.png){.nostretch fig-align="right" height="280"}


## Clay predictions

![](../figures/progress_october_turing/class_acc.png){.nostretch fig-align="left" height="430"}


## Summary: model comparison

- Clay is the winner!
- Training loss is important
- Some classes still very much underdetected!


## Next steps

- Technical write-up
- Hyperparameter-tuning
- Data augmentation
- Comparison to baseline
    - downsample/ upsample
    - maps

---

