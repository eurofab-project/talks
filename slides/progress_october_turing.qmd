---
title: "Progress meeting October"
subtitle: "AI model design"
author: "Eurofab team"
institute: "Alan Turing Institute"
# date: "today"
format:
  revealjs:
    theme: 
      - default
      - ../assets/reveal.scss
    logo: ../assets/icon.svg
    menu: false
    transition: slide
    navigation-mode: linear
    controls-layout: edges
    progress: true
    include-in-header: ../assets/font.html
    title-slide-attributes:
      data-background-image: ../assets/logos.png
      data-background-size: 20%
      data-background-position: 50% 90%
---

# Overview
- **AI model design:** June-October 2024
- **AI model development and training:** September-November 2024
- **European space-time urban strategy:** December-March 2025


## Review: AI model design
* **Scale:** Pixel vs patch (size)
* **Task:** Classification vs segmentation
* **Model:** Network architectures and foundation models


# Baseline


![](../figures/progress_october_turing/baseline_tile_level.png){.nostretch fig-align="center" height="400"}


# WP 202 AI model design

![](../figures/progress_october_turing/overview.png){.nostretch fig-align="center"}


## Data preprocessing

* 224 x 224 x 3 image tiles
    - 26,942 tiles (.tif)

* Labels:
    - Spatial signatures (.tif)

- Train/test split: stratified 80/20% (stratified by distribution in dataset)

---

### Train/test 
80/20%
![](../figures/progress_october_turing/train_df.png){.nostretch fig-align="left" height="400"}
![](../figures/progress_october_turing/test_df.png){.nostretch fig-align="right" height="400"}


---

### Example

![](../figures/progress_october_turing/random_sample.png){.nostretch fig-align="center" height="400"}

---

### Unbalanced dataset
![](../figures/progress_october_turing/unbalanced.png){.nostretch fig-align="center" height="400"}


## Model design
![](../figures/progress_october_turing/example.png){.nostretch fig-align="center"}

## Model design
![](../figures/progress_october_turing/setup.png){.nostretch fig-align="center"}


## Backbone foundation models

- Satlas
- Clay
- IBM/NASA (Prithvi)

![](../figures/202408_progress_august_AT/foundation_models.png){.nostretch fig-align="center" height="200"}


---

## Comparison of backbones

| Model | Model | #Labels | Images |
|---------|:-----|------:|:------:|
| Satlas   | SwinT    | 302 million | Sentinel-2  |
| Clay     | MAE/ViT  | 70 million  |Sentinel-2/Landsat/NAIP/LINZ |
| IBM/NASA | MAE/ViT  | 250 PB |  Sentinel-2/Landsat   |


## Loss

* **CrossEntropy Loss** ("ce"):
    - penalizes pixel-wise misclassifications

* **Focal Loss** ("focal"):
    - reeduces the contribution of easily classified examples and puts more weight on hard-to-classify pixels.

## Validation metric

* **IoU** (Intersection over Union)
    - Overlap between predicted and ground truth segmentations; 0 (no overlap) to 1 (perfect overlap).

* **F1 Score** (Weighted)
    - Balancing precision (how much of the prediction is correct) and recall (how much of the actual segmentation is captured).

* **Accuracy** (Weighted)
    - Percentage of correctly classified pixels.

---

### Model A: Satlas
![](../figures/progress_october_turing/satlas_model.png){.nostretch fig-align="center" height="400"}

---

### Model B: Clay
![](../figures/progress_october_turing/clay_model.png){.nostretch fig-align="center" height="400"}

---

### Model C: Prithvi
![](../figures/progress_october_turing/prithvi_model.png){.nostretch fig-align="center" height="400"}



### Results: fine-tuning

| Model          | Satlas | Clay   | Prithvi |
|----------------|--------|--------|---------|
| Run time (per epoch) (with GPU)  | 9 mins | 8 mins | 20 mins |
| # parameters      | 90M | 86M  | 120M |
| Ease of implementation/adding changes | 5/10   | 6/10   | 7/10    |
| Hyperparameter experiments/tracking   | Own set up | Wandb.ai | Tensorboard |
| Accuracy                            | 0.57   | 0.66   | 0.62    |
| IoU (weighted) (0-1)               | 0.33  | 0.58  | 0.41   |
| F1 (weighted)               | 0.41  | 0.69  | 0.58   |


No hyperparameter tuning!


### Results: fine-tuning focal loss

| Model          | Satlas | Clay   | Prithvi |
|----------------|--------|--------|---------|
| Accuracy        | 0.25  | 0.66   | 0.59     |
| IoU (weighted) (0-1)  | 0.2  | 0.58  | 0.42   |
| F1 (weighted)     | 0.21  | 0.69  | 0.59    |


## CE vs focal loss

![](../figures/progress_october_turing/class_acc_ce_loss.png){.nostretch fig-align="left" height="200"}
![](../figures/progress_october_turing/class_acc_focal_loss_prithvi.png){.nostretch fig-align="right" height="200"}


## Clay predictions

[insert heatmap]


## Summary: model comparison

- Training loss is important
- Clay architecture
- Some classes still undetected!

## Next steps

- Technical write-up
- Hyerparameter-tuning
- Comparison to baseline

---

